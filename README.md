# IronRegression-Quest

![](https://github.com/goncalocostacarvalho/IronRegression-Quest/blob/main/IronRegression-Quest.png)

# Project Overview ğŸ’»

## Context <br /> 
In this project, itâ€™s provided a dataset (CSV file) of house sale prices for King County, including Seattle, over an one year period from May 2014 to May 2015. <br /> Link to dataset: https://www.kaggle.com/datasets/minasameh55/king-country-houses-aa

## Main Task <br /> 
Develop a machine learning model to predict the house sale prices

## Approach <br /> 
Doing several notebooks with slightly differences between them and checking the results <br /> I will only present the final results on this README file and upload the last notebook

# Exploring the data ğŸ”

| Function | Output |
| :---: | :---: |
| .shape | 21613 rows and 21 columns |
| .dtypes | 1 categorical column (date), 20 numerical columns (5 as float) |
| .isnull().sum() | 0 null values |
| .eq(" ").sum() | 0 empty values |
| .multiplicated().sum() | 0 multiplicate values |

# EDA ğŸ“Š

- Part of the EDA was to analyze all the distributions for every column
- After analysis, I decided to transform only this 3 columns and treated them as boolean:
| waterfront | view | yr_renovated |
| :---: | :---: | :---: |
|   |   |   |
  

# Results ğŸ’¥

![](https://github.com/goncalocostacarvalho/IronRegression-Quest/blob/main/IronRegression-Quest-Results.png)

# Conclusions ğŸ’­

- Less data doesn't mean a more accurate model
- Accuracy results doesn't change too much with the data cleaning and featuring engineering
- XGBoost got the best results suggesting a non linear relationship between features and target
